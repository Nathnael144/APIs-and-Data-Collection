{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4788d79a",
   "metadata": {},
   "source": [
    "# **Introduction to web scraping**\n",
    "Web scraping, also known as web harvesting or web data extraction, is the process of extracting information from websites or web pages. It involves automated retrieval of data from web sources. \n",
    "People use it for various applications such as data analysis, mining, price comparison, content aggregation, and more.\n",
    "\n",
    "## How web scraping works\n",
    "### HTTP request\n",
    "The process typically begins with an HTTP request. A web scraper sends an HTTP request to a specific URL, similar to how a web browser would when you visit a website. The request is usually an HTTP GET request, which retrieves the web page's content.\n",
    "\n",
    "### Web page retrieval\n",
    "The web server hosting the website responds to the request by returning the requested web page's HTML content. This content includes the visible text and media elements and the underlying HTML structure that defines the page's layout.\n",
    "\n",
    "### HTML parsing\n",
    "Once the HTML content is received, you need to parse the content. Parsing involves breaking down the HTML structure into components, such as tags, attributes, and text content. You can use BeautifulSoup in Python. It creates a structured representation of the HTML content that can be easily navigated and manipulated.\n",
    "\n",
    "### Data extraction\n",
    "With the HTML content parsed, web scrapers can now identify and extract the specific data they need. This data can include text, links, images, tables, product prices, news articles, and more. Scrapers locate the data by searching for relevant HTML tags, attributes, and patterns in the HTML structure.\n",
    "\n",
    "### Data transformation\n",
    "Extracted data may need further processing and transformation. For instance, you can remove HTML tags from text, convert data formats, or clean up messy data. This step ensures the data is ready for analysis or other use cases.\n",
    "\n",
    "### Storage\n",
    "After extraction and transformation, you can store the scraped data in various formats, such as databases, spreadsheets, JSON, or CSV files. The choice of storage format depends on the specific project's requirements.\n",
    "\n",
    "### Automation\n",
    "In many cases, scripts or programs automate web scraping. These automation tools allow recurring data extraction from multiple web pages or websites. Automated scraping is especially useful for collecting data from dynamic websites that regularly update their content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a16fa23",
   "metadata": {},
   "source": [
    "### Web scraping\n",
    "Web scraping involves extracting information from web pages using Python. It can save time and automate data collection.\n",
    "\n",
    "### Required tools\n",
    "Web scraping requires Python code and two essential modules: Requests and Beautiful Soup. Ensure you have both modules installed in your Python environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94bb865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Beautiful Soup to parse the web page content\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befac90a",
   "metadata": {},
   "source": [
    "### Fetching and parsing HTML\n",
    "To start web scraping, you need to fetch the HTML content of a webpage and parse it using Beautiful Soup. Here's a step-by-step example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcb05a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please set a user-agent and respect our robot policy https://w.wiki/4wJS. See also https://phabricator.wikimedia.org/T400119.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nathanel Biresaw\\AppData\\Local\\Temp\\ipykernel_5336\\3092050995.py:10: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_content, 'html.parser')\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# Specify the URL of the webpage you want to scrape\n",
    "url = 'https://en.wikipedia.org/wiki/IBM'\n",
    "# Send an HTTP GET request to the webpage\n",
    "response = requests.get(url)\n",
    "# Store the HTML content in a variable\n",
    "html_content = response.text\n",
    "# Create a BeautifulSoup object to parse the HTML\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "# Display a snippet of the HTML content\n",
    "print(html_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366ef7b7",
   "metadata": {},
   "source": [
    "### Navigating the HTML structure\n",
    "BeautifulSoup represents HTML content as a tree-like structure, allowing for easy navigation. You can use methods like find_all to filter and extract specific HTML elements. For example, to find all anchor tags () and print their text:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfff78b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all <a> tags (anchor tags) in the HTML\n",
    "links = soup.find_all('a')\n",
    "# Iterate through the list of links and print their text\n",
    "for link in links:\n",
    "    print(link.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a63993b",
   "metadata": {},
   "source": [
    "### Custom data extraction\n",
    "Web scraping allows you to navigate the HTML structure and extract specific information based on your requirements. This process may involve finding specific tags, attributes, or text content within the HTML document.\n",
    "\n",
    "### Using BeautifulSoup for HTML parsing\n",
    "Beautiful Soup is a powerful tool for navigating and extracting specific web page parts. It allows you to find elements based on their tags, attributes, or text, making extracting the information you're interested in easier.\n",
    "\n",
    "### Using pandas read_html for table extraction\n",
    "Pandas, a Python library, provides a function called read_html, which can automatically extract data from websites' tables and present it in a format suitable for analysis. Itâ€™s similar to taking a table from a webpage and importing it into a spreadsheet for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50c6dc5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
